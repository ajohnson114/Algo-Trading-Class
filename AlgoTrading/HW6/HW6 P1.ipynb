{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a14fe06b",
   "metadata": {},
   "source": [
    "## Finalized Version in cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de32cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "np.random.seed(6996)\n",
    "\n",
    "# error term\n",
    "epsilon_vec = np.random.normal(0,1,500).reshape(500,1)\n",
    "# X_matrix or regressors or predictiors\n",
    "X_mat = np.random.normal(0,2,size = (500,500))\n",
    "# Slope\n",
    "slope_vec = np.random.uniform(1,5,500)\n",
    "# Simulate Ys\n",
    "Y_mat = 1 + np.cumsum(X_mat * slope_vec,axis=1)[:,1:] + epsilon_vec\n",
    "# each col of Y_mat representing one simulation vector: starting with 2 regressors, end with 500\n",
    "\n",
    "\n",
    "# Question 1: Fit linear regression\n",
    "\n",
    "def fit_lr(X, Y, N_feature=10, split_ratio=0.7, out_put=True):\n",
    "    train_size = np.int(len(X) * split_ratio)\n",
    "    X_train = X_mat[0:train_size, 0:N_feature]\n",
    "    Y_train = Y_mat[0:train_size, N_feature - 2]\n",
    "    X_test = X_mat[train_size:, 0:N_feature]\n",
    "    Y_test = Y_mat[train_size:, N_feature - 2]\n",
    "    # Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(X_train, Y_train)\n",
    "    # model evaluation\n",
    "    mse_in = np.mean(np.power((regr.predict(X_train) - Y_train),2)) # To be completed\n",
    "    mse_out = np.mean(np.power((regr.predict(X_test) - Y_test),2)) # # To be completed\n",
    "    if out_put:\n",
    "        print('Coefficients for first %d predictors: \\n' % N_feature, regr.coef_)\n",
    "    print('\\n In-sample Mean Square Error: ', mse_in)\n",
    "    print('Out-of-sample Mean Square Error: ', mse_out)\n",
    "\n",
    "    return regr.coef_, mse_out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 2: Ridge\n",
    "\n",
    "def fit_ridge():\n",
    "    ## subset data\n",
    "    N_feature = 10\n",
    "    split_ratio = 0.7\n",
    "    train_size = np.int64(len(X_mat)*split_ratio)\n",
    "    X_train = X_mat[0:train_size,0:N_feature]\n",
    "    Y_train = Y_mat[0:train_size,N_feature-2]\n",
    "    X_test = X_mat[train_size:,0:N_feature]\n",
    "    Y_test = Y_mat[train_size:,N_feature-2]\n",
    "    ## Ridge from sklearn\n",
    "    # You will use ridge with the following parameters:\n",
    "    #alphas=[5**i for i in range(-8,2)],cv=5\n",
    "    \n",
    "    ridge_cv = linear_model.RidgeCV(alphas = [5**i for i in range(-8,2)], cv=5)\n",
    "    ridge_cv.fit(X_train, Y_train) # To be completed\n",
    "    return ridge_cv,X_train,Y_train,X_test,Y_test\n",
    "\n",
    "\n",
    "# Question 3: Lasso\n",
    "\n",
    "def fit_lasso(X, Y, N_feature=10, out_put = True):\n",
    "    X_sub= X_mat[:,0:N_feature]\n",
    "    Y_sub = Y_mat[:,N_feature-2]\n",
    "    # Create linear regression object using Lasso\n",
    "    # To be completed\n",
    "    regr = linear_model.LassoCV(cv=3)\n",
    "    regr.fit(X_sub, Y_sub)\n",
    "    mse = np.mean(np.power((regr.predict(X_sub) - Y_sub),2))\n",
    "    \n",
    "    if out_put:\n",
    "        print('Coefficients for first %d predictors: \\n' %N_feature,regr.coef_)\n",
    "    print('Mean Square Error: ', mse)\n",
    "    print('Best alpha for Lasso',regr.alpha_)\n",
    "    return regr.coef_, mse\n",
    "def question1():\n",
    "    ## 10 predictors & 491 predictors\n",
    "    m10_coef, m10_mse = fit_lr(X_mat, Y_mat)\n",
    "\n",
    "    ## If we apply 490 predictors, based on the small train sample size, the result would not make sense.\n",
    "    ## The difference of in/out sample error is a good indicator of overfitting\n",
    "    v490_coef, v490_mse = fit_lr(X_mat, Y_mat, N_feature=490, out_put=False)\n",
    "\n",
    "    print(m10_coef[:5], m10_mse )\n",
    "    print(v490_coef[:5], v490_mse)\n",
    "\n",
    "\n",
    "def question2():\n",
    "    ridge_cv,X_train, Y_train, X_test, Y_test = fit_ridge()\n",
    "    mse_in = np.mean(np.square(Y_train - ridge_cv.predict(X_train)))\n",
    "    mse_out = np.mean(np.square(Y_test - ridge_cv.predict(X_test)))\n",
    "    print('best_alpha: ',ridge_cv.alpha_)\n",
    "    print('Regression Coefficients: \\n',ridge_cv.coef_)\n",
    "    print('In-sample Mean Square Loss: ',mse_in)\n",
    "    print('Out-of-Sample Mean Square Loss: ', mse_out)\n",
    "\n",
    "\n",
    "def question3():\n",
    "    ## 10 predictors & 491 predictors\n",
    "    m10_coef, m10_mse = fit_lasso(X_mat, Y_mat)\n",
    "\n",
    "    v490_coef, v490_mse = fit_lasso(X_mat, Y_mat, N_feature=490, out_put=False)\n",
    "\n",
    "    mark_zeros = np.where(v490_coef == 0.0)\n",
    "\n",
    "    print(m10_coef[:5], m10_mse)\n",
    "    print(v490_coef[:5], v490_mse)\n",
    "    print(mark_zeros[:5])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    func_name = input().strip()\n",
    "    globals()[func_name]()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
