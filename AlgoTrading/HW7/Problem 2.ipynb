{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63185b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "def imputation(df):\n",
    "    # use SimpleImputer to impute the missing values as mean of the column they are in\n",
    "    # use missing_values = np.nan and strategy = 'mean'\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp_data = imputer.fit_transform(df)\n",
    "    # print the imputed value at df.iloc[1,23], keep 6 decimal places\n",
    "    print(imp_data[1,23])\n",
    "    # return imputed data\n",
    "    return imp_data\n",
    "    \n",
    "    \n",
    "def split_train_test(imp_data):\n",
    "    X = imp_data[:,:-1]\n",
    "    y = imp_data[:, -1]\n",
    "    \n",
    "    # split train and test set with train_test_split method in sklean\n",
    "    # the test size is 30% of the data and set random_state=0\n",
    "    # since bankruptcy label is likely to be unbalanced, set stratify=y\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=.7, random_state=0, stratify=y)\n",
    "    \n",
    "    # print the value at position (0,0) of X_train\n",
    "    print(X_train[0,0])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "def normalization(X_train, X_test, y_train, y_test):\n",
    "    # normalize X_train and X_test by StandardScaler in sklearn\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    #print(X_test)\n",
    "    # print the value at position (0,0) of X_test, keep 7 decimal places\n",
    "    out = X_test[0][0]\n",
    "    print(\"{:.7f}\".format(out))\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def dimension_reduction_LR(X_train, X_test, y_train, y_test):\n",
    "    # you will selection the most important two features in this example using Logistic Regression\n",
    "    # we will add a l1 penalty term (Lasso) to regularize the coefficient\n",
    "    # tune the tolerance level Î» from 1 to 0.1 to 0.01 to 0.001 (the regularization parameter in Lasso is C)\n",
    "    # until you find there are only two predictors that has nonzero coefficient\n",
    "    # fit the logistic regressor using LogisticRegression() in sklearn \n",
    "    # set the solver='liblinear', random_state=0, and also the l1 penalty term\n",
    "    \n",
    "    # find the ideal tolerance level by trial and error, and print it \n",
    "    lr = LogisticRegression(penalty='l1', solver= 'liblinear', random_state=0,C=.01)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(lr.C)\n",
    "    # print the coefficient of the two features as a List\n",
    "    coefs = [i for i in lr.coef_[0] if i!= 0]\n",
    "    x = np.array(coefs)\n",
    "    #x = \"[{:.7f} {:.8f}]\".format(coefs[0], coefs[1])\n",
    "    print(x)\n",
    "    # reset X_train and X_test with only the two most important predictors\n",
    "    cols = pd.DataFrame(X_train)\n",
    "    predictors = [cols.columns[i] for i in range(len(lr.coef_[0])) if lr.coef_[0][i] != 0]\n",
    "    X_train = X_train[:,predictors]\n",
    "    X_test = X_test[:,predictors]\n",
    "    # i.e. drop the less important features\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "def SVM(X_train, X_test, y_train, y_test):\n",
    "    # fit the SVM model to use the two features to predict bankrupcy\n",
    "    # set the kernel as 'rbf', gamma=0.2, C=1 and random_state=0\n",
    "    svm = SVC(gamma=.2,random_state=0)\n",
    "    svm.fit(X_train, y_train)\n",
    "    # print training accuracy, keep 6 decimal places\n",
    "    trainacc = svm.score(X_train,y_train)\n",
    "    print(\"{:.6f}\".format(trainacc))\n",
    "    # print the test accuracy, keep 6 decimal places\n",
    "    testacc = svm.score(X_test,y_test)\n",
    "    print(\"{:.6f}\".format(testacc))\n",
    "\n",
    "def test_0(df):\n",
    "    imp_data = imputation(df)\n",
    "    \n",
    "def test_1(df):\n",
    "    imp_data = imputation(df)\n",
    "    X_train, X_test, y_train, y_test = split_train_test(imp_data)\n",
    "    \n",
    "def test_2(df):\n",
    "    imp_data = imputation(df)\n",
    "    X_train, X_test, y_train, y_test = split_train_test(imp_data)\n",
    "    X_train, X_test, y_train, y_test = normalization(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "def test_3(df):\n",
    "    imp_data = imputation(df)\n",
    "    X_train, X_test, y_train, y_test = split_train_test(imp_data)\n",
    "    X_train, X_test, y_train, y_test = normalization(X_train, X_test, y_train, y_test)\n",
    "    X_train, X_test, y_train, y_test = dimension_reduction_LR(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "def test_4(df):\n",
    "    imp_data = imputation(df)\n",
    "    X_train, X_test, y_train, y_test = split_train_test(imp_data)\n",
    "    X_train, X_test, y_train, y_test = normalization(X_train, X_test, y_train, y_test)\n",
    "    X_train, X_test, y_train, y_test = dimension_reduction_LR(X_train, X_test, y_train, y_test)\n",
    "    SVM(X_train, X_test, y_train, y_test)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_id = int(input().strip())\n",
    "    row_num = int(input().strip())\n",
    "    Data = []\n",
    "    col_names = list(map(str, input().split(',')))\n",
    "    for i in range(row_num):\n",
    "        line=list(map(str, input().split(',')))\n",
    "        for j in range(1,65):\n",
    "            if line[j] == '':\n",
    "                line[j] = np.nan\n",
    "            else:\n",
    "                line[j] = float(line[j])\n",
    "        line[65] = int(eval(line[65]))\n",
    "        Data.append(line[1:])\n",
    "    df = pd.DataFrame(Data, columns= col_names[1:])\n",
    "    \n",
    "    if test_id == 0:\n",
    "        test_0(df)\n",
    "    if test_id == 1:\n",
    "        test_1(df)\n",
    "    if test_id == 2:\n",
    "        test_2(df)\n",
    "    if test_id == 3:\n",
    "        test_3(df)\n",
    "    if test_id == 4:\n",
    "        test_4(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
