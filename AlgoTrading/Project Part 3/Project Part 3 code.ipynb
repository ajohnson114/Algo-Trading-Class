{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c91c38f7",
   "metadata": {},
   "source": [
    "Project is based on this github repo: https://github.com/rorysroes/SGX-Full-OrderBook-Tick-Data-Trading-Strategy/blob/master/Model_Selection/Model_Selection.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_string = \"\"\"0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64\n",
    "0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,58.5,0.9663865546,1.238095238,0.1063829787,0.625,-0.2307692308,27.66666667,0.9302325581,17.03448276,0.8891013384,11.64935065,0.841889117,8.395833333,0.7871396896,6.217391304,0.7228915663,12.23611111,0.8488982162,6.504761905,0.7335025381,3.923076923,0.59375,1.827622015,0.292691884,2.569767442,0.4397394137,3.483660131,0.5539358601,4.656716418,0.6464379947,1.532051282,0.2101265823,2.462585034,0.4223968566\n",
    "0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,58.5,0.9663865546,1.238095238,0.1063829787,0.625,-0.2307692308,27.66666667,0.9302325581,17.03448276,0.8891013384,11.64935065,0.841889117,8.395833333,0.7871396896,6.217391304,0.7228915663,12.23611111,0.8488982162,6.504761905,0.7335025381,3.923076923,0.59375,1.827622015,0.292691884,2.569767442,0.4397394137,3.483660131,0.5539358601,4.656716418,0.6464379947,1.532051282,0.2101265823,2.462585034,0.4223968566\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,2,0.3333333333,0.3,-0.5384615385,3.6,0.5652173913,0.8275862069,-0.09433962264,0.5833333333,-0.2631578947,0.4776119403,-0.3535353535,0.4186046512,-0.4098360656,0.380952381,-0.4482758621,1.087719298,0.04201680672,1.176470588,0.08108108108,1.419354839,0.1733333333,0.3274725275,-0.5066225166,0.3209876543,-0.5140186916,0.3356643357,-0.497382199,0.3548387097,-0.4761904762,2.396396396,0.4111405836,1.803571429,0.2866242038\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,2,0.3333333333,0.3,-0.5384615385,1.125,0.05882352941,0.8275862069,-0.09433962264,0.5833333333,-0.2631578947,0.4776119403,-0.3535353535,0.4186046512,-0.4098360656,0.380952381,-0.4482758621,0.7848101266,-0.1205673759,0.7751937985,-0.1266375546,0.8301886792,-0.09278350515,0.3235613464,-0.5110746514,0.3209876543,-0.5140186916,0.3356643357,-0.497382199,0.3548387097,-0.4761904762,1.003773585,0.001883239171,0.9099099099,-0.04716981132\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,2,0.3333333333,0.03333333333,-0.935483871,0.8571428571,-0.07692307692,0.126984127,-0.7746478873,0.07608695652,-0.8585858586,0.05850091408,-0.8894645941,0.04958677686,-0.905511811,0.04419889503,-0.9153439153,0.1515892421,-0.7367303609,0.1589825119,-0.7256515775,0.197309417,-0.670411985,0.03667240955,-0.9292497626,0.03606102635,-0.9303882195,0.03800475059,-0.9267734554,0.0405904059,-0.9219858156,0.4061068702,-0.4223669924,0.2686170213,-0.5765199161\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,2,0.3333333333,0.03333333333,-0.935483871,0.880952381,-0.06329113924,0.126984127,-0.7746478873,0.07608695652,-0.8585858586,0.05850091408,-0.8894645941,0.04958677686,-0.905511811,0.04419889503,-0.9153439153,0.1540342298,-0.7330508475,0.1621621622,-0.7209302326,0.201793722,-0.6641791045,0.03673394044,-0.9291352603,0.03606102635,-0.9303882195,0.03800475059,-0.9267734554,0.0405904059,-0.9219858156,0.4167938931,-0.411637931,0.2752659574,-0.5683003128\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,2,0.3333333333,0.03333333333,-0.935483871,1.595238095,0.2293577982,0.126984127,-0.7746478873,0.07608695652,-0.8585858586,0.05850091408,-0.8894645941,0.04958677686,-0.905511811,0.04419889503,-0.9153439153,0.2273838631,-0.6294820717,0.2575516693,-0.590391909,0.33632287,-0.4966442953,0.03857986709,-0.9257064992,0.03606102635,-0.9303882195,0.03800475059,-0.9267734554,0.0405904059,-0.9219858156,0.7374045802,-0.151142355,0.4747340426,-0.3561767358\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,3,0.5,0.03333333333,-0.935483871,1.595238095,0.2293577982,0.1746031746,-0.7027027027,0.09782608696,-0.8217821782,0.07129798903,-0.866894198,0.05785123967,-0.890625,0.04972375691,-0.9052631579,0.2444987775,-0.6070726916,0.2655007949,-0.5804020101,0.3408071749,-0.491638796,0.03919517598,-0.9245662857,0.0374479889,-0.9278074866,0.04038004751,-0.9223744292,0.0442804428,-0.9151943463,0.7389312977,-0.1501316945,0.477393617,-0.3537353735\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,3,0.5,0.03333333333,-0.935483871,1.595238095,0.2293577982,0.1746031746,-0.7027027027,0.09782608696,-0.8217821782,0.07129798903,-0.866894198,0.05785123967,-0.890625,0.04972375691,-0.9052631579,0.2444987775,-0.6070726916,0.2655007949,-0.5804020101,0.3408071749,-0.491638796,0.03919517598,-0.9245662857,0.0374479889,-0.9278074866,0.04038004751,-0.9223744292,0.0442804428,-0.9151943463,0.7389312977,-0.1501316945,0.477393617,-0.3537353735\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,3,0.5,0.03888888889,-0.9251336898,1.595238095,0.2293577982,0.1798941799,-0.6950672646,0.1032608696,-0.8128078818,0.07678244973,-0.857385399,0.06336088154,-0.8808290155,0.05524861878,-0.8952879581,0.2493887531,-0.6007827789,0.2702702703,-0.5744680851,0.3452914798,-0.4866666667,0.04473295594,-0.9143648036,0.04299583911,-0.9175531915,0.04592240697,-0.9121877366,0.04981549816,-0.9050966608,0.7419847328,-0.148115688,0.4813829787,-0.3500897666\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,3,0.5,0.03888888889,-0.9251336898,1.833333333,0.2941176471,0.1798941799,-0.6950672646,0.1032608696,-0.8128078818,0.07678244973,-0.857385399,0.06336088154,-0.8808290155,0.05524861878,-0.8952879581,0.2738386308,-0.5700575816,0.3020667727,-0.536019536,0.3901345291,-0.4387096774,0.04534826483,-0.9132379775,0.04299583911,-0.9175531915,0.04592240697,-0.9121877366,0.04981549816,-0.9050966608,0.8488549618,-0.08175061932,0.5478723404,-0.2920962199\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,3,0.5,0.03888888889,-0.9251336898,1.119047619,0.05617977528,0.1798941799,-0.6950672646,0.1032608696,-0.8128078818,0.07678244973,-0.857385399,0.06336088154,-0.8808290155,0.05524861878,-0.8952879581,0.2004889976,-0.66598778,0.2066772655,-0.6574440053,0.2556053812,-0.5928571429,0.04350233817,-0.9166224424,0.04299583911,-0.9175531915,0.04592240697,-0.9121877366,0.04981549816,-0.9050966608,0.5282442748,-0.3086913087,0.3484042553,-0.483234714\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,5,0.6666666667,0.03888888889,-0.9251336898,1.119047619,0.05617977528,0.2751322751,-0.5684647303,0.1467391304,-0.7440758294,0.1023765996,-0.8142620232,0.07988980716,-0.8520408163,0.06629834254,-0.8756476684,0.2347188264,-0.6198019802,0.2225755167,-0.6358907672,0.264573991,-0.5815602837,0.04473295594,-0.9143648036,0.04576976422,-0.9124668435,0.05067300079,-0.9035418237,0.05719557196,-0.8917975567,0.5312977099,-0.3060817547,0.3537234043,-0.4774066798\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,6,0.7142857143,0.03888888889,-0.9251336898,1.119047619,0.05617977528,0.3227513228,-0.512,0.1684782609,-0.711627907,0.1151736746,-0.793442623,0.08815426997,-0.8379746835,0.07182320442,-0.8659793814,0.2518337408,-0.59765625,0.2305246423,-0.6253229974,0.269058296,-0.5759717314,0.04534826483,-0.9132379775,0.04715672677,-0.9099337748,0.0530482977,-0.8992481203,0.06088560886,-0.8852173913,0.5328244275,-0.3047808765,0.3563829787,-0.4745098039\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,6,0.7142857143,0.03888888889,-0.9251336898,1.119047619,0.05617977528,0.3227513228,-0.512,0.1684782609,-0.711627907,0.1151736746,-0.793442623,0.08815426997,-0.8379746835,0.07182320442,-0.8659793814,0.2518337408,-0.59765625,0.2305246423,-0.6253229974,0.269058296,-0.5759717314,0.04534826483,-0.9132379775,0.04715672677,-0.9099337748,0.0530482977,-0.8992481203,0.06088560886,-0.8852173913,0.5328244275,-0.3047808765,0.3563829787,-0.4745098039\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,6,0.7142857143,0.03888888889,-0.9251336898,1.119047619,0.05617977528,0.3227513228,-0.512,0.1684782609,-0.711627907,0.1151736746,-0.793442623,0.08815426997,-0.8379746835,0.07182320442,-0.8659793814,0.2518337408,-0.59765625,0.2305246423,-0.6253229974,0.269058296,-0.5759717314,0.04534826483,-0.9132379775,0.04715672677,-0.9099337748,0.0530482977,-0.8992481203,0.06088560886,-0.8852173913,0.5328244275,-0.3047808765,0.3563829787,-0.4745098039\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,6,0.7142857143,0.03888888889,-0.9251336898,1.119047619,0.05617977528,0.3227513228,-0.512,0.1684782609,-0.711627907,0.1151736746,-0.793442623,0.08815426997,-0.8379746835,0.07182320442,-0.8659793814,0.2518337408,-0.59765625,0.2305246423,-0.6253229974,0.269058296,-0.5759717314,0.04534826483,-0.9132379775,0.04715672677,-0.9099337748,0.0530482977,-0.8992481203,0.06088560886,-0.8852173913,0.5328244275,-0.3047808765,0.3563829787,-0.4745098039\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,6,0.7142857143,0.03888888889,-0.9251336898,1.119047619,0.05617977528,0.3227513228,-0.512,0.1684782609,-0.711627907,0.1151736746,-0.793442623,0.08815426997,-0.8379746835,0.07182320442,-0.8659793814,0.2518337408,-0.59765625,0.2305246423,-0.6253229974,0.269058296,-0.5759717314,0.04534826483,-0.9132379775,0.04715672677,-0.9099337748,0.0530482977,-0.8992481203,0.06088560886,-0.8852173913,0.5328244275,-0.3047808765,0.3563829787,-0.4745098039\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,6,0.7142857143,0.03888888889,-0.9251336898,1.119047619,0.05617977528,0.3227513228,-0.512,0.1684782609,-0.711627907,0.1151736746,-0.793442623,0.08815426997,-0.8379746835,0.07182320442,-0.8659793814,0.2518337408,-0.59765625,0.2305246423,-0.6253229974,0.269058296,-0.5759717314,0.04534826483,-0.9132379775,0.04715672677,-0.9099337748,0.0530482977,-0.8992481203,0.06088560886,-0.8852173913,0.5328244275,-0.3047808765,0.3563829787,-0.4745098039\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,6,0.7142857143,0.03888888889,-0.9251336898,1.119047619,0.05617977528,0.3227513228,-0.512,0.1684782609,-0.711627907,0.1151736746,-0.793442623,0.08815426997,-0.8379746835,0.07182320442,-0.8659793814,0.2518337408,-0.59765625,0.2305246423,-0.6253229974,0.269058296,-0.5759717314,0.04534826483,-0.9132379775,0.04715672677,-0.9099337748,0.0530482977,-0.8992481203,0.06088560886,-0.8852173913,0.5328244275,-0.3047808765,0.3563829787,-0.4745098039\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,6,0.7142857143,0.03888888889,-0.9251336898,1.119047619,0.05617977528,0.3227513228,-0.512,0.1684782609,-0.711627907,0.1151736746,-0.793442623,0.08815426997,-0.8379746835,0.07182320442,-0.8659793814,0.2518337408,-0.59765625,0.2305246423,-0.6253229974,0.269058296,-0.5759717314,0.04534826483,-0.9132379775,0.04715672677,-0.9099337748,0.0530482977,-0.8992481203,0.06088560886,-0.8852173913,0.5328244275,-0.3047808765,0.3563829787,-0.4745098039\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,6,0.7142857143,0.03888888889,-0.9251336898,1.119047619,0.05617977528,0.3227513228,-0.512,0.1684782609,-0.711627907,0.1151736746,-0.793442623,0.08815426997,-0.8379746835,0.07182320442,-0.8659793814,0.2518337408,-0.59765625,0.2305246423,-0.6253229974,0.269058296,-0.5759717314,0.04534826483,-0.9132379775,0.04715672677,-0.9099337748,0.0530482977,-0.8992481203,0.06088560886,-0.8852173913,0.5328244275,-0.3047808765,0.3563829787,-0.4745098039\n",
    "1,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,0.21097,6,0.7142857143,0.03888888889,-0.9251336898,1.119047619,0.05617977528,0.3227513228,-0.512,0.1684782609,-0.711627907,0.1151736746,-0.793442623,0.08815426997,-0.8379746835,0.07182320442,-0.8659793814,0.2518337408,-0.59765625,0.2305246423,-0.6253229974,0.269058296,-0.5759717314,0.04534826483,-0.9132379775,0.04715672677,-0.9099337748,0.0530482977,-0.8992481203,0.06088560886,-0.8852173913,0.5328244275,-0.3047808765,0.3563829787,-0.4745098039\n",
    "1,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,1,0,0.03333333333,-0.935483871,0.1666666667,-0.7142857143,0.07936507937,-0.8529411765,0.05434782609,-0.8969072165,0.04570383912,-0.9125874126,0.04132231405,-0.9206349206,0.03867403315,-0.9255319149,0.06356968215,-0.8804597701,0.05882352941,-0.8888888889,0.06278026906,-0.8818565401,0.0342727049,-0.9337259801,0.0346740638,-0.9329758713,0.03562945368,-0.9311926606,0.036900369,-0.9288256228,0.09465648855,-0.8270571827,0.07313829787,-0.863692689\n",
    "1,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,1,0,0.03333333333,-0.935483871,0.1666666667,-0.7142857143,0.07936507937,-0.8529411765,0.05434782609,-0.8969072165,0.04570383912,-0.9125874126,0.04132231405,-0.9206349206,0.03867403315,-0.9255319149,0.06356968215,-0.8804597701,0.05882352941,-0.8888888889,0.06278026906,-0.8818565401,0.0342727049,-0.9337259801,0.0346740638,-0.9329758713,0.03562945368,-0.9311926606,0.036900369,-0.9288256228,0.09465648855,-0.8270571827,0.07313829787,-0.863692689\n",
    "1,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,1,0,0.02777777778,-0.9459459459,0.1666666667,-0.7142857143,0.07407407407,-0.8620689655,0.04891304348,-0.9067357513,0.04021937843,-0.9226713533,0.03581267218,-0.9308510638,0.03314917127,-0.935828877,0.0586797066,-0.8891454965,0.05405405405,-0.8974358974,0.05829596413,-0.8898305085,0.02873492493,-0.9441354148,0.02912621359,-0.9433962264,0.03008709422,-0.9415833974,0.03136531365,-0.939177102,0.09160305344,-0.8321678322,0.06914893617,-0.8706467662\n",
    "1,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,1,0,0.02777777778,-0.9459459459,0.1666666667,-0.7142857143,0.07407407407,-0.8620689655,0.04891304348,-0.9067357513,0.04021937843,-0.9226713533,0.03581267218,-0.9308510638,0.03314917127,-0.935828877,0.0586797066,-0.8891454965,0.05405405405,-0.8974358974,0.05829596413,-0.8898305085,0.02873492493,-0.9441354148,0.02912621359,-0.9433962264,0.03008709422,-0.9415833974,0.03136531365,-0.939177102,0.09160305344,-0.8321678322,0.06914893617,-0.8706467662\n",
    "1,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,1,0,0.02777777778,-0.9459459459,0.1666666667,-0.7142857143,0.07407407407,-0.8620689655,0.04891304348,-0.9067357513,0.04021937843,-0.9226713533,0.03581267218,-0.9308510638,0.03314917127,-0.935828877,0.0586797066,-0.8891454965,0.05405405405,-0.8974358974,0.05829596413,-0.8898305085,0.02873492493,-0.9441354148,0.02912621359,-0.9433962264,0.03008709422,-0.9415833974,0.03136531365,-0.939177102,0.09160305344,-0.8321678322,0.06914893617,-0.8706467662\n",
    "1,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,1,0,0.02777777778,-0.9459459459,0.1666666667,-0.7142857143,0.07407407407,-0.8620689655,0.04891304348,-0.9067357513,0.04021937843,-0.9226713533,0.03581267218,-0.9308510638,0.03314917127,-0.935828877,0.0586797066,-0.8891454965,0.05405405405,-0.8974358974,0.05829596413,-0.8898305085,0.02873492493,-0.9441354148,0.02912621359,-0.9433962264,0.03008709422,-0.9415833974,0.03136531365,-0.939177102,0.09160305344,-0.8321678322,0.06914893617,-0.8706467662\n",
    "1,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,1,0,0.02777777778,-0.9459459459,0.1666666667,-0.7142857143,0.07407407407,-0.8620689655,0.04891304348,-0.9067357513,0.04021937843,-0.9226713533,0.03581267218,-0.9308510638,0.03314917127,-0.935828877,0.0586797066,-0.8891454965,0.05405405405,-0.8974358974,0.05829596413,-0.8898305085,0.02873492493,-0.9441354148,0.02912621359,-0.9433962264,0.03008709422,-0.9415833974,0.03136531365,-0.939177102,0.09160305344,-0.8321678322,0.06914893617,-0.8706467662\n",
    "1,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,1,0,0.02777777778,-0.9459459459,0.1666666667,-0.7142857143,0.07407407407,-0.8620689655,0.04891304348,-0.9067357513,0.04021937843,-0.9226713533,0.03581267218,-0.9308510638,0.03314917127,-0.935828877,0.0586797066,-0.8891454965,0.05405405405,-0.8974358974,0.05829596413,-0.8898305085,0.02873492493,-0.9441354148,0.02912621359,-0.9433962264,0.03008709422,-0.9415833974,0.03136531365,-0.939177102,0.09160305344,-0.8321678322,0.06914893617,-0.8706467662\n",
    "1,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,1,0,0.02777777778,-0.9459459459,0.2142857143,-0.6470588235,0.07407407407,-0.8620689655,0.04891304348,-0.9067357513,0.04021937843,-0.9226713533,0.03581267218,-0.9308510638,0.03314917127,-0.935828877,0.06356968215,-0.8804597701,0.06041335453,-0.8860569715,0.06726457399,-0.8739495798,0.02885798671,-0.9439028766,0.02912621359,-0.9433962264,0.03008709422,-0.9415833974,0.03136531365,-0.939177102,0.1129770992,-0.7969821674,0.08244680851,-0.8476658477\n",
    "1,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,3,0.5,0.02222222222,-0.9565217391,0.2380952381,-0.6153846154,0.164021164,-0.7181818182,0.08695652174,-0.84,0.06032906764,-0.8862068966,0.04683195592,-0.9105263158,0.03867403315,-0.9255319149,0.09535452323,-0.8258928571,0.0747217806,-0.8609467456,0.07623318386,-0.8583333333,0.0246123554,-0.9519577228,0.02635228849,-0.9486486486,0.02929532858,-0.9430769231,0.0332103321,-0.9357142857,0.1236641221,-0.7798913043,0.09042553191,-0.8341463415\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.01666666667,-0.9672131148,0.09523809524,-0.8260869565,0.4545454545,-0.375,0.01865222623,-0.9633786178,0.02099737533,-0.9588688946,0.02380952381,-0.9534883721,0.02724358974,-0.9469578783,0.03153153153,-0.9388646288,0.02855051245,-0.9444839858,0.04392523364,-0.9158460161,0.06967213115,-0.8697318008,0.07140307033,-0.8667110963,0.05459770115,-0.8964577657,0.04436450839,-0.9150401837,0.03703703704,-0.9285714286,0.1937799043,-0.6753507014,0.1140939597,-0.7951807229\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.01666666667,-0.9672131148,0.09523809524,-0.8260869565,0.4545454545,-0.375,0.01865222623,-0.9633786178,0.02099737533,-0.9588688946,0.02380952381,-0.9534883721,0.02724358974,-0.9469578783,0.03153153153,-0.9388646288,0.02855051245,-0.9444839858,0.04392523364,-0.9158460161,0.06967213115,-0.8697318008,0.07140307033,-0.8667110963,0.05459770115,-0.8964577657,0.04436450839,-0.9150401837,0.03703703704,-0.9285714286,0.1937799043,-0.6753507014,0.1140939597,-0.7951807229\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.01111111111,-0.978021978,0.09523809524,-0.8260869565,0.4545454545,-0.375,0.01323706378,-0.973871734,0.0157480315,-0.9689922481,0.01875901876,-0.9631728045,0.02243589744,-0.9561128527,0.02702702703,-0.9473684211,0.02342606149,-0.9542203147,0.03925233645,-0.9244604317,0.06557377049,-0.8769230769,0.06961799357,-0.8698264352,0.05172413793,-0.9016393443,0.04076738609,-0.9216589862,0.0329218107,-0.9362549801,0.1913875598,-0.6787148594,0.110738255,-0.8006042296\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.01111111111,-0.978021978,0.09523809524,-0.8260869565,0.4545454545,-0.375,0.01323706378,-0.973871734,0.0157480315,-0.9689922481,0.01875901876,-0.9631728045,0.02243589744,-0.9561128527,0.02702702703,-0.9473684211,0.02342606149,-0.9542203147,0.03925233645,-0.9244604317,0.06557377049,-0.8769230769,0.06961799357,-0.8698264352,0.05172413793,-0.9016393443,0.04076738609,-0.9216589862,0.0329218107,-0.9362549801,0.1913875598,-0.6787148594,0.110738255,-0.8006042296\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.01111111111,-0.978021978,0.09523809524,-0.8260869565,0.4545454545,-0.375,0.01323706378,-0.973871734,0.0157480315,-0.9689922481,0.01875901876,-0.9631728045,0.02243589744,-0.9561128527,0.02702702703,-0.9473684211,0.02342606149,-0.9542203147,0.03925233645,-0.9244604317,0.06557377049,-0.8769230769,0.06961799357,-0.8698264352,0.05172413793,-0.9016393443,0.04076738609,-0.9216589862,0.0329218107,-0.9362549801,0.1913875598,-0.6787148594,0.110738255,-0.8006042296\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.01176470588,-0.976744186,0.4,-0.4285714286,0.3333333333,-0.5,0.01428571429,-0.9718309859,0.01739130435,-0.9658119658,0.02131147541,-0.9582664526,0.02641509434,-0.9485294118,0.03333333333,-0.935483871,0.02875399361,-0.9440993789,0.05186721992,-0.9013806706,0.09009009009,-0.8347107438,0.1491294474,-0.7404479578,0.08571428571,-0.8421052632,0.05862068966,-0.8892508143,0.04324324324,-0.9170984456,0.2231404959,-0.6351351351,0.1482758621,-0.7417417417\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.01176470588,-0.976744186,0.5,-0.3333333333,0.3333333333,-0.5,0.01493506494,-0.9705694178,0.01884057971,-0.9630156472,0.0237704918,-0.9535628503,0.03018867925,-0.9413919414,0.03888888889,-0.9251336898,0.0303514377,-0.9410852713,0.05497925311,-0.8957718781,0.09459459459,-0.8271604938,0.1831945496,-0.6903390915,0.1047619048,-0.8103448276,0.07068965517,-0.8679549114,0.05135135135,-0.9023136247,0.2272727273,-0.6296296296,0.1534482759,-0.7339312407\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.01176470588,-0.976744186,0.5,-0.3333333333,0.3333333333,-0.5,0.01493506494,-0.9705694178,0.01884057971,-0.9630156472,0.0237704918,-0.9535628503,0.03018867925,-0.9413919414,0.03888888889,-0.9251336898,0.0303514377,-0.9410852713,0.05497925311,-0.8957718781,0.09459459459,-0.8271604938,0.1831945496,-0.6903390915,0.1047619048,-0.8103448276,0.07068965517,-0.8679549114,0.05135135135,-0.9023136247,0.2272727273,-0.6296296296,0.1534482759,-0.7339312407\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.005882352941,-0.9883040936,0.5,-0.3333333333,0.3333333333,-0.5,0.009090909091,-0.981981982,0.01304347826,-0.974248927,0.01803278689,-0.9645732689,0.02452830189,-0.9521178637,0.03333333333,-0.935483871,0.02476038339,-0.9516757599,0.04979253112,-0.9051383399,0.09009009009,-0.8347107438,0.1794095382,-0.6957637997,0.1,-0.8181818182,0.06551724138,-0.8770226537,0.04594594595,-0.9121447028,0.2252066116,-0.6323777403,0.15,-0.7391304348\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.005882352941,-0.9883040936,0.7,-0.1764705882,0.3333333333,-0.5,0.01038961039,-0.9794344473,0.01594202899,-0.9686162625,0.02295081967,-0.9551282051,0.0320754717,-0.9378427788,0.04444444444,-0.914893617,0.02795527157,-0.9456099456,0.05601659751,-0.8939096267,0.0990990991,-0.8196721311,0.2475397426,-0.6031553398,0.1380952381,-0.7573221757,0.08965517241,-0.835443038,0.06216216216,-0.8829516539,0.2334710744,-0.621440536,0.1603448276,-0.7236255572\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.005882352941,-0.9883040936,0.7,-0.1764705882,0.3333333333,-0.5,0.01038961039,-0.9794344473,0.01594202899,-0.9686162625,0.02295081967,-0.9551282051,0.0320754717,-0.9378427788,0.04444444444,-0.914893617,0.02795527157,-0.9456099456,0.05601659751,-0.8939096267,0.0990990991,-0.8196721311,0.2475397426,-0.6031553398,0.1380952381,-0.7573221757,0.08965517241,-0.835443038,0.06216216216,-0.8829516539,0.2334710744,-0.621440536,0.1603448276,-0.7236255572\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.005882352941,-0.9883040936,0.7,-0.1764705882,0.3333333333,-0.5,0.01038961039,-0.9794344473,0.01594202899,-0.9686162625,0.02295081967,-0.9551282051,0.0320754717,-0.9378427788,0.04444444444,-0.914893617,0.02795527157,-0.9456099456,0.05601659751,-0.8939096267,0.0990990991,-0.8196721311,0.2475397426,-0.6031553398,0.1380952381,-0.7573221757,0.08965517241,-0.835443038,0.06216216216,-0.8829516539,0.2334710744,-0.621440536,0.1603448276,-0.7236255572\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.01176470588,-0.976744186,0.7,-0.1764705882,0.3333333333,-0.5,0.01623376623,-0.9680511182,0.02173913043,-0.9574468085,0.02868852459,-0.9442231076,0.03773584906,-0.9272727273,0.05,-0.9047619048,0.03354632588,-0.9350850077,0.0612033195,-0.8846529814,0.1036036036,-0.812244898,0.251324754,-0.5983061101,0.1428571429,-0.75,0.09482758621,-0.8267716535,0.06756756757,-0.8734177215,0.2355371901,-0.618729097,0.1637931034,-0.7185185185\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.01176470588,-0.976744186,0.7,-0.1764705882,0.3333333333,-0.5,0.01623376623,-0.9680511182,0.02173913043,-0.9574468085,0.02868852459,-0.9442231076,0.03773584906,-0.9272727273,0.05,-0.9047619048,0.03354632588,-0.9350850077,0.0612033195,-0.8846529814,0.1036036036,-0.812244898,0.251324754,-0.5983061101,0.1428571429,-0.75,0.09482758621,-0.8267716535,0.06756756757,-0.8734177215,0.2355371901,-0.618729097,0.1637931034,-0.7185185185\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.01176470588,-0.976744186,0.7,-0.1764705882,0.3333333333,-0.5,0.01623376623,-0.9680511182,0.02173913043,-0.9574468085,0.02868852459,-0.9442231076,0.03773584906,-0.9272727273,0.05,-0.9047619048,0.03354632588,-0.9350850077,0.0612033195,-0.8846529814,0.1036036036,-0.812244898,0.251324754,-0.5983061101,0.1428571429,-0.75,0.09482758621,-0.8267716535,0.06756756757,-0.8734177215,0.2355371901,-0.618729097,0.1637931034,-0.7185185185\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.01176470588,-0.976744186,0.7,-0.1764705882,0.3333333333,-0.5,0.01623376623,-0.9680511182,0.02173913043,-0.9574468085,0.02868852459,-0.9442231076,0.03773584906,-0.9272727273,0.05,-0.9047619048,0.03354632588,-0.9350850077,0.0612033195,-0.8846529814,0.1036036036,-0.812244898,0.251324754,-0.5983061101,0.1428571429,-0.75,0.09482758621,-0.8267716535,0.06756756757,-0.8734177215,0.2355371901,-0.618729097,0.1637931034,-0.7185185185\n",
    "0,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.14065,0.01176470588,-0.976744186,0.7,-0.1764705882,0.3333333333,-0.5,0.01623376623,-0.9680511182,0.02173913043,-0.9574468085,0.02868852459,-0.9442231076,0.03773584906,-0.9272727273,0.05,-0.9047619048,0.03354632588,-0.9350850077,0.0612033195,-0.8846529814,0.1036036036,-0.812244898,0.251324754,-0.5983061101,0.1428571429,-0.75,0.09482758621,-0.8267716535,0.06756756757,-0.8734177215,0.2355371901,-0.618729097,0.1637931034,-0.7185185185\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import io\n",
    "import unittest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier,\\\n",
    "                              GradientBoostingClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class Model_Selection:\n",
    "    \n",
    "    def __init__(self,models,model_grid_params,data_2014,latest_sec,pred_sec,day):\n",
    "        \n",
    "        self.models = models\n",
    "        self.model_grid = model_grid_params\n",
    "        self.data_2014 = data_2014\n",
    "        self.latest_sec = latest_sec\n",
    "        self.pred_sec = pred_sec\n",
    "        self.day = day\n",
    "        self.keys = models.keys()\n",
    "        self.best_score = {}\n",
    "        self.grid = {}\n",
    "        self.predict_values = {}\n",
    "        self.cv_acc = {}\n",
    "        self.acc = {}\n",
    "        self.fscore = {}\n",
    "        self.true_values = {}\n",
    "        self.predict_values_day = {}\n",
    "        self.cv_acc_day = {}\n",
    "        self.acc_day = {}\n",
    "        self.fscore_day = {}\n",
    "        self.true_values_day = {}\n",
    "        self.summary_day = []\n",
    "        \n",
    "    def Grid_fit(self,X_train,y_train,cv = 2,scoring = 'accuracy'):\n",
    "        \n",
    "        # Tune parameters for each model in self.keys\n",
    "        for key in self.keys:\n",
    "            # define model\n",
    "            \n",
    "            # use GridSearchCV to search for best parameters\n",
    "            \n",
    "            # Store the GridSearchCV object into a variable called Grid\n",
    "            # Let self.grid[key] = Grid\n",
    "            # append the best accuracy to self.acc[key]\n",
    "            #print(\"Running GridSearchCV for %s.\" %(key))\n",
    "            model = self.models[key]\n",
    "            model_grid = self.model_grid[key]\n",
    "            Grid = GridSearchCV(model, model_grid, cv = cv, scoring = scoring)\n",
    "            Grid.fit(X_train,y_train) \n",
    "            self.grid[key] = Grid\n",
    "            #print(Grid.best_params_)\n",
    "            #print('CV Best Score = %s'%(Grid.best_score_))\n",
    "            self.cv_acc[key].append(Grid.best_score_)  \n",
    "            \n",
    "\n",
    "            pass \n",
    "    \n",
    "    def model_fit(self,X_train, y_train, X_test, y_test):\n",
    "        \n",
    "        # fit each algorithm in self.keys for given data\n",
    "        # \n",
    "        for key in self.keys:\n",
    "\n",
    "            # define model/algorithm here\n",
    "            \n",
    "            # set parameter using the best_params_ obtained after calling Grid_fit (assume you have already called Grid_fit)\n",
    "            \n",
    "            # fit model with X_train and y_train\n",
    "            \n",
    "            # predict using trained model on X_test\n",
    "            \n",
    "            # Calculate accuracy and f1_score\n",
    "            \n",
    "            #print \"Running training & testing for %s.\" %(key)\n",
    "            model = self.models[key]\n",
    "            model.set_params(**self.grid[key].best_params_)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_test)\n",
    "            #print 'Prediction latest 15 second = %s'%(predictions)\n",
    "            self.predict_values[key].append(predictions.tolist())\n",
    "            self.true_values[key].append(y_test.tolist())\n",
    "            acc = metrics.accuracy_score(y_test,predictions)\n",
    "            f_score = metrics.f1_score(y_test,predictions)\n",
    "            #print 'Accuracy = %s'%(acc)\n",
    "            self.acc[key].append(acc)\n",
    "            self.fscore[key].append(f_score)\n",
    "            \n",
    "            \n",
    "            if key == 'SVC':\n",
    "                if list(self.grid[key].best_params_.values())[0] == 'linear':\n",
    "                    feature_imp = dict(zip([i for i in range(0,64,1)],model.coef_[0]))\n",
    "                    Top_five = sorted(feature_imp.items(),key = lambda x : x[1] , reverse=True)[0:5]\n",
    "                else:\n",
    "                    pass\n",
    "            else: \n",
    "                feature_imp = dict(zip([i for i in range(0,64,1)],model.feature_importances_))\n",
    "                Top_five = sorted(feature_imp.items(),key = lambda x : x[1] , reverse=True)[0:5]\n",
    "                pass\n",
    "\n",
    "    def pipline(self):\n",
    "        # This is the main method, where you train algorithms for each set of \n",
    "        # hyperparameters on each day. And store statistics in the mean time.\n",
    "        \n",
    "        # looping through days (in our case, the we only have the data for one day 50 seconds)\n",
    "        for day in range(0,self.day,1):\n",
    "            # call set_list() to initialize the corresponding properties\n",
    "            # call set_list_day() to initialize the corresponding properties\n",
    "            self.set_list() # store values\n",
    "            self.set_list_day()\n",
    "            # don't print\n",
    "            for i in range(0, 20, self.pred_sec):\n",
    "                # only two rolling windows here\n",
    "                # for data in each day for each rolling window of training and test data\n",
    "                # run grid_fit to find best parameter for each algorithm\n",
    "                # then run model_fit to obtain stats for algorithms\n",
    "                # Remember, label is the first column of data and the remaining columns are features\n",
    "                #print '--------------------Rolling Window Time = %s--------------------'%(i/pred_sec)\n",
    "                # Train data\n",
    "                data_train = self.data_2014[day][i:i+self.latest_sec]\n",
    "                X_train = data_train.drop(['0'],axis=1)#,'65','66','67'],axis=1)\n",
    "                y_train = data_train['0']\n",
    "\n",
    "                # Test data\n",
    "                data_test = self.data_2014[day][i + self.latest_sec:i + self.latest_sec + self.pred_sec]\n",
    "                X_test = data_test.drop(['0'],axis=1)#,'65','66','67'],axis=1)\n",
    "                y_test = data_test['0']\n",
    "                \n",
    "                #start = time.time()\n",
    "                self.Grid_fit(X_train, y_train, cv = 5, scoring = 'accuracy')\n",
    "                self.model_fit(X_train, y_train,X_test,y_test)\n",
    "                #end = time.time()\n",
    "                #print 'Total Time = %s'%(end - start)\n",
    "                pass\n",
    "\n",
    "            for key in self.keys:\n",
    "                # append values of set_list properties to set_list_day properties\n",
    "                self.cv_acc_day[key].append(self.cv_acc[key])\n",
    "                self.acc_day[key].append(self.acc[key])\n",
    "                self.fscore_day[key].append(self.fscore[key])\n",
    "                self.true_values_day[key].append(self.true_values[key])\n",
    "                self.predict_values_day[key].append(self.predict_values[key])\n",
    "                pass\n",
    "\n",
    "            # append score_summary(sort_by = 'Accuracy_mean')) to summary_day\n",
    "            self.summary_day.append(self.score_summary(sort_by = 'Accuracy_mean'))\n",
    "            pass\n",
    "    \n",
    "    def set_list(self):\n",
    "        # Initialize predict_values, cv_acc, acc, fscore, true_values properties (these are stats for a specific day)\n",
    "        # for each method in self.keys, the corresponding value of the above dictionaries are empty list\n",
    "        for key in self.keys:\n",
    "            self.predict_values[key] = []\n",
    "            self.cv_acc[key] = []\n",
    "            self.acc[key] = []\n",
    "            self.fscore[key] = []\n",
    "            self.true_values[key] = []\n",
    "        pass\n",
    "            \n",
    "    def set_list_day(self):\n",
    "        # Initialize predict_values_day, cv_acc_day, acc_day, fscore_day, true_values_day properties (these are stats for all days)\n",
    "        # for each method in self.keys, the corresponding value of the above dictionaries are empty list\n",
    "        for key in self.keys:\n",
    "            self.predict_values_day[key] = []\n",
    "            self.cv_acc_day[key] = []\n",
    "            self.acc_day[key] = []\n",
    "            self.fscore_day[key] = []\n",
    "            self.true_values_day[key] = []\n",
    "        pass\n",
    "\n",
    "            \n",
    "    def score_summary(self,sort_by):\n",
    "        # Create a dataframe called summary\n",
    "        # summary should contain 6 columns of order 'Estimator','Accuracy_mean','Accuracy_std','Accuracy_max','Accuracy_min','F_score'\n",
    "        # Rows of summary is sorted according to sort_by in descending order\n",
    "        # Index of summary is named 'Ranking'\n",
    "        # return summary\n",
    "        #\n",
    "        # summary looks like \n",
    "        #\n",
    "        #                                 Estimator  Accuracy_mean  Accuracy_std  \\\n",
    "        # Ranking                                                            \n",
    "        # 0            RandomForestClassifier           0.65          0.35   \n",
    "        # 1              ExtraTreesClassifier           0.65          0.35   \n",
    "        # 3        GradientBoostingClassifier           0.65          0.35   \n",
    "        # 4                               SVC           0.65          0.35   \n",
    "        # 2                AdaBoostClassifier           0.40          0.10   \n",
    "\n",
    "        #         Accuracy_max  Accuracy_min   F_score  \n",
    "        # Ranking                                        \n",
    "        # 0                 1.0           0.3  0.230769  \n",
    "        # 1                 1.0           0.3  0.230769  \n",
    "        # 3                 1.0           0.3  0.230769  \n",
    "        # 4                 1.0           0.3  0.230769  \n",
    "        # 2                 0.5           0.3  0.230769 \n",
    "        summary = pd.concat([pd.DataFrame(self.acc.keys()),pd.DataFrame(map(lambda x: np.mean(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: np.std(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: max(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: min(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: np.mean(self.fscore[x]), self.fscore))],axis=1)\n",
    "        summary.columns = ['Estimator','Accuracy_mean','Accuracy_std','Accuracy_max','Accuracy_min','F_score']\n",
    "        summary.index.rename('Ranking', inplace=True)\n",
    "        return summary.sort_values(by = [sort_by], ascending=False)\n",
    "          \n",
    "          \n",
    "    def print_(self):\n",
    "        print(self.predict_values)\n",
    "\n",
    "        \n",
    "def run_pipline(models, model_grid_params, data_2014_up, latest_sec=30, pred_sec=10, day=1):\n",
    "    # Use Model_Selection class, define an object of the class called pip\n",
    "    # run pipline() method\n",
    "    # return pip\n",
    "    \n",
    "    # Some useful info:\n",
    "    #\n",
    "    # Machine learning algorithm\n",
    "    # Best model will be selected among models\n",
    "    # models = {\n",
    "    #     'RandomForestClassifier': RandomForestClassifier(random_state = 0),\n",
    "    #     'ExtraTreesClassifier': ExtraTreesClassifier(random_state = 0),\n",
    "    #     'AdaBoostClassifier': AdaBoostClassifier(base_estimator = DecisionTreeClassifier(),\\\n",
    "    #                                              n_estimators = 10,random_state = 0),\n",
    "    #     'GradientBoostingClassifier': GradientBoostingClassifier(random_state = 0),\n",
    "    #     'SVC': SVC(probability=True,random_state = 0),\n",
    "    # }\n",
    "    # parameters set for each model\n",
    "    # Best parameter will be selected based on training data\n",
    "    # model_grid_params = {\n",
    "    #     'RandomForestClassifier': {'max_features':[None],'n_estimators':[10],'max_depth':[10],\\\n",
    "    #                                'min_samples_split':[2],'criterion':['entropy'],\\\n",
    "    #                                'min_samples_leaf':[3]},\n",
    "    #     'ExtraTreesClassifier': {'max_features':[None],'n_estimators':[10],'max_depth':[10],\\\n",
    "    #                              'min_samples_split':[2],'criterion':['entropy'],\\\n",
    "    #                              'min_samples_leaf':[3]},\n",
    "    #     'AdaBoostClassifier': {\"base_estimator__criterion\" : [\"entropy\"],\\\n",
    "    #                            \"base_estimator__max_depth\": [None],\\\n",
    "    #                            \"base_estimator__min_samples_leaf\" : [3],\\\n",
    "    #                            \"base_estimator__min_samples_split\" : [2],\\\n",
    "    #                            \"base_estimator__max_features\" : [None]},\n",
    "    #     'GradientBoostingClassifier': {'max_features':[None],'n_estimators':[10],'max_depth':[10],\\\n",
    "    #                                    'min_samples_split':[2],'min_samples_leaf':[3],\\\n",
    "    #                                    'learning_rate':[0.1],'subsample':[1.0]},\n",
    "    #     'SVC': [{'kernel':['rbf'],'gamma':[1e-1],'C':[1]},\\\n",
    "    #             {'kernel':['linear'],'C':[1,10]}]\n",
    "    # }\n",
    "    # latest_sec : length of training data (in seconds)\n",
    "    # pred_sec : length test data (in second)\n",
    "    # day : on a specific day\n",
    "    # \n",
    "    # data_2014_up:\n",
    "    # Each row is the data (featrues and label) for a second on a specific day\n",
    "    # 50 rows in total (50 secs)\n",
    "    # Column = 0 : label[0 : not traded,1 : traded]     &   Column = 1:end : Features values\n",
    "\n",
    "    pip = Model_Selection(models,model_grid_params,data_2014_up,latest_sec,pred_sec,day)\n",
    "    pip.pipline()\n",
    "    return pip\n",
    "\n",
    "class test_Model_Selection(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.models = {\n",
    "        'RandomForestClassifier': RandomForestClassifier(random_state = 0),\n",
    "        'ExtraTreesClassifier': ExtraTreesClassifier(random_state = 0),\n",
    "        'AdaBoostClassifier': AdaBoostClassifier(base_estimator = DecisionTreeClassifier(),\\\n",
    "                                                 n_estimators = 10,random_state = 0),\n",
    "        'GradientBoostingClassifier': GradientBoostingClassifier(random_state = 0),\n",
    "        'SVC': SVC(probability=True,random_state = 0),\n",
    "        }\n",
    "        self.model_grid_params = {\n",
    "        'RandomForestClassifier': {'max_features':[None],'n_estimators':[10],'max_depth':[10],\\\n",
    "                                   'min_samples_split':[2],'criterion':['entropy'],\\\n",
    "                                   'min_samples_leaf':[3]},\n",
    "        'ExtraTreesClassifier': {'max_features':[None],'n_estimators':[10],'max_depth':[10],\\\n",
    "                                 'min_samples_split':[2],'criterion':['entropy'],\\\n",
    "                                 'min_samples_leaf':[3]},\n",
    "        'AdaBoostClassifier': {\"base_estimator__criterion\" : [\"entropy\"],\\\n",
    "                               \"base_estimator__max_depth\": [None],\\\n",
    "                               \"base_estimator__min_samples_leaf\" : [3],\\\n",
    "                               \"base_estimator__min_samples_split\" : [2],\\\n",
    "                               \"base_estimator__max_features\" : [None]},\n",
    "        'GradientBoostingClassifier': {'max_features':[None],'n_estimators':[10],'max_depth':[10],\\\n",
    "                                       'min_samples_split':[2],'min_samples_leaf':[3],\\\n",
    "                                       'learning_rate':[0.1],'subsample':[1.0]},\n",
    "        'SVC': [{'kernel':['rbf'],'gamma':[1e-1],'C':[1]},\\\n",
    "                {'kernel':['linear'],'C':[1,10]}]\n",
    "        }\n",
    "        self.data = []\n",
    "        self.data.append(pd.read_csv(io.StringIO(data_string)))\n",
    "        self.latest_sec = 30\n",
    "        self.pred_sec = 10\n",
    "        self.day = 1\n",
    "    \n",
    "    def test1(self):\n",
    "        pip = Model_Selection(self.models, self.model_grid_params, self.data, self.latest_sec, self.pred_sec, self.day)\n",
    "        if pip.grid == {}:\n",
    "            print('test1: pass')\n",
    "        else:\n",
    "            print('test1: failed')\n",
    "\n",
    "    def test2(self):\n",
    "        pip = Model_Selection(self.models, self.model_grid_params, self.data, self.latest_sec, self.pred_sec, self.day)\n",
    "        if pip.true_values_day == {}:\n",
    "            print('test2: pass')\n",
    "        else:\n",
    "            print('test2: failed')\n",
    "    \n",
    "    def test3(self):\n",
    "        pip = run_pipline(self.models, self.model_grid_params, self.data)\n",
    "        self.assertEqual(list(pip.summary_day[0].columns), ['Estimator', 'Accuracy_mean', 'Accuracy_std', 'Accuracy_max', 'Accuracy_min', 'F_score'])\n",
    "    \n",
    "    def test4(self):\n",
    "        pip = run_pipline(self.models, self.model_grid_params, self.data)\n",
    "        print(pip.summary_day[0]['Estimator'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tmp = test_Model_Selection()\n",
    "    tmp.setUp()\n",
    "    func_name = input().strip()\n",
    "    tmp.__getattribute__(func_name)()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
